{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Intro to NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Basics of NumPy array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Data manipulation in Python is nearly synonymous with NumPy array manipulation</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>NumPy Array Attributes:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(0)  # seed for reproducibility\n",
    "\n",
    "x1 = np.random.randint(10, size=6)  # One-dimensional array\n",
    "x2 = np.random.randint(10, size=(3, 4))  # Two-dimensional array\n",
    "x3 = np.random.randint(10, size=(3, 4, 5))  # Three-dimensional array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"x3 ndim: \", x3.ndim)\n",
    "print(\"x3 shape:\", x3.shape)\n",
    "print(\"x3 size: \", x3.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"dtype:\", x3.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"itemsize:\", x3.itemsize, \"bytes\")\n",
    "print(\"nbytes:\", x3.nbytes, \"bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Full Array:\",x1)\n",
    "print (\"0th element:\",x1[0])\n",
    "print (x1[4])\n",
    "print (x1[-1])\n",
    "print (x1[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (x2)\n",
    "print (x2[0, 0])\n",
    "print (x2[2, 0])\n",
    "print (x2[2, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2[0, 0] = 12\n",
    "x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1[0] = 3.14159  # this will be truncated!\n",
    "x1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Array Slicing: Accessing Subarrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Just as we can use square brackets to access individual array elements, we can also use them to access subarrays with the slice notation, marked by the colon (:) character.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>x[start:stop:step]</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(10)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (x[:5])  # first five elements\n",
    "print (x[5:])  # elements after index 5\n",
    "print (x[4:7]) # middle sub-array\n",
    "print (x[::2]) # every other element\n",
    "print (x[1::2])# every other element, starting at index 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Multi-dimensional</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (x2[:2, :3]) # two rows, three columns\n",
    "print (x2[:3, ::2])  #all rows, every other column\n",
    "print (x2[::-1, ::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Accessing array rows and columns</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x2[:, 0])  # first column of x2\n",
    "print(x2[0, :])  # first row of x2\n",
    "print(x2[0])  # equivalent to x2[0, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Subarrays as no-copy views</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x2)\n",
    "x2_sub = x2[:2, :2]\n",
    "print(x2_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x2_sub[0, 0] = 99\n",
    "print(x2_sub)\n",
    "print(x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Creating copies of arrays</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2_sub_copy = x2[:2, :2].copy()\n",
    "print(x2_sub_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2_sub_copy[0, 0] = 42\n",
    "print(x2_sub_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Reshaping array:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = np.arange(1, 10).reshape((3, 3))\n",
    "print(grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Concatenation of arrays:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1, 2, 3])\n",
    "y = np.array([3, 2, 1])\n",
    "np.concatenate([x, y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = [99, 99, 99]\n",
    "print(np.concatenate([x, y, z]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = np.array([[1, 2, 3],\n",
    "                 [4, 5, 6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate along the first axis\n",
    "np.concatenate([grid, grid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate along the second axis (zero-indexed)\n",
    "np.concatenate([grid, grid], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Splitting of array:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [1, 2, 3, 99, 99, 3, 2, 1]\n",
    "x1, x2, x3 = np.split(x, [3, 5])\n",
    "print(x1, x2, x3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Useful NumPy Function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(4)\n",
    "print (x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.add(x, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Operator\tEquivalent ufunc\tDescription</b>\n",
    "\\+\t`np.add`\tAddition (e.g., 1 + 1 = 2)<br>\n",
    "\\-\t`np.subtract`\tSubtraction (e.g., 3 - 2 = 1)<br>\n",
    "\\-\t`np.negative`\tUnary negation (e.g., -2)<br>\n",
    "\\*\t`np.multiply`\tMultiplication (e.g., 2 * 3 = 6)<br>\n",
    "/\t`np.divide`\tDivision (e.g., 3 / 2 = 1.5)<br>\n",
    "//\t`np.floor_divide`\tFloor division (e.g., 3 // 2 = 1)<br>\n",
    "\\**\t`np.power`\tExponentiation (e.g., 2 ** 3 = 8)<br>\n",
    "%\t`np.mod`\tModulus/remainder (e.g., 9 % 4 = 1)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([-2, -1, 0, 1, 2])\n",
    "np.abs(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Trigonometric functions:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [-1, 0, 1]\n",
    "print(\"x         = \", x)\n",
    "print(\"arcsin(x) = \", np.arcsin(x))\n",
    "print(\"arccos(x) = \", np.arccos(x))\n",
    "print(\"arctan(x) = \", np.arctan(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Exponents and logarithms</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [1, 2, 3]\n",
    "print(\"x     =\", x)\n",
    "print(\"e^x   =\", np.exp(x))\n",
    "print(\"2^x   =\", np.exp2(x))\n",
    "print(\"3^x   =\", np.power(3, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [1, 2, 4, 10]\n",
    "print(\"x        =\", x)\n",
    "print(\"ln(x)    =\", np.log(x))\n",
    "print(\"log2(x)  =\", np.log2(x))\n",
    "print(\"log10(x) =\", np.log10(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregations: Min, Max, and Everything In Between"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = np.random.random(100)\n",
    "sum(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_array = np.random.rand(1000000)\n",
    "%timeit sum(big_array)\n",
    "%timeit np.sum(big_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = np.random.random((3, 4))\n",
    "print(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M.min(axis=0) #within each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M.max(axis=1) #within each row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>other aggregations:</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Name\t  NaN-safe Version\tDescription</b><br>\n",
    "`np.sum`\t`np.nansum`\tCompute sum of elements<br>\n",
    "`np.prod`\t`np.nanprod`\tCompute product of elements<br>\n",
    "`np.mean`\t`np.nanmean`\tCompute mean of elements<br>\n",
    "`np.std`\t`np.nanstd`\tCompute standard deviation<br>\n",
    "`np.var`\t`np.nanvar`\tCompute variance<br>\n",
    "`np.min`\t`np.nanmin`\tFind minimum value<br>\n",
    "`np.max`\t`np.nanmax`\tFind maximum value<br>\n",
    "`np.argmin`\t`np.nanargmin`\tFind index of minimum value<br>\n",
    "`np.argmax`\t`np.nanargmax`\tFind index of maximum value<br>\n",
    "`np.median`\t`np.nanmedian`\tCompute median of elements<br>\n",
    "`np.percentile`\t`np.nanpercentile`\tCompute rank-based statistics of elements<br>\n",
    "`np.any`\t`N/A`\tEvaluate whether any elements are true<br>\n",
    "`np.all`\t`N/A`\tEvaluate whether all elements are true<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparisons, Masks, and Boolean Logic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1, 2, 3, 4, 5])\n",
    "print (x)\n",
    "print (x < 3) # less than\n",
    "print (x > 3) # greater than\n",
    "print (x <= 3)# less than or equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.less(x, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`==`\t`np.equal`\t\t<br>\n",
    "`!=`\t`np.not_equal`<br>\n",
    "`<`\t`np.less`\t\t<br>\n",
    "`<=`\t`np.less_equal`<br>\n",
    "`>`\t`np.greater`\t\t<br>\n",
    "`>=`\t`np.greater_equal`<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(0)\n",
    "x = rng.randint(10, size=(3, 4))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x < 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Working with Boolean Arrays:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x)\n",
    "# how many values less than 6?\n",
    "#To count the number of True entries in a Boolean array, np.count_nonzero is useful:\n",
    "np.count_nonzero(x < 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another way to get at this information is to use np.sum; in this case, False is interpreted as 0, and True is interpreted as 1:\n",
    "np.sum(x < 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many values less than 6 in each row?\n",
    "#The benefit of sum() is that like with other NumPy aggregation functions, this summation can be done along rows or columns as well:\n",
    "np.sum(x < 6, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f we're interested in quickly checking whether any or all the values are true, we can use (you guessed it) np.any or np.all:\n",
    "np.any(x > 8)\n",
    "np.any(x < 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting Arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Fast Sorting in NumPy: np.sort and np.argsort:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To return a sorted version of the array without modifying the input, you can use np.sort:\n",
    "x = np.array([2, 1, 4, 3, 5])\n",
    "np.sort(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If you prefer to sort the array in-place, you can instead use the sort method of arrays:\n",
    "x.sort()\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A related function is argsort, which instead returns the indices of the sorted elements:\n",
    "x = np.array([2, 1, 4, 3, 5])\n",
    "i = np.argsort(x)\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Sorting along rows or columns:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand = np.random.RandomState(42)\n",
    "X = rand.randint(0, 10, (4, 6))\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort each column of X\n",
    "np.sort(X, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort each row of X\n",
    "np.sort(X, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Partial Sorts: Partitioning:</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes we're not interested in sorting the entire array, but simply want to find the k smallest values in the array. NumPy provides this in the np.partition function. np.partition takes an array and a number K; the result is a new array with the smallest K values to the left of the partition, and the remaining values to the right, in arbitrary order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([7, 2, 3, 1, 6, 5, 4])\n",
    "np.partition(x, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Intro to Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Pandas objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>We'll be looking at two main objects of the Pandas library namely, Series and DataFrames.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1 Series\n",
    "A series object is one-dimensional array/list of values that are indexed. Think of it like an indexed 'series' of values. \n",
    "<br>Let's look at some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List -> Series\n",
    "numbers = pd.Series([1, 2, 3.4, 5.67, 8, 0.9])\n",
    "\n",
    "names = pd.Series(['Alane', 'Ayanna', 'Tyisha', 'Jarvis', 'Tabetha', 'Geoffrey', 'Ken'])\n",
    "\n",
    "print(numbers, '\\n')\n",
    "print(names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see a default index is added to the list of values. Lets add a <b>custom index</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_index = 'abcdef'\n",
    "\n",
    "# Please note how we use the attribute 'values' for a series object\n",
    "numbers2 = pd.Series(numbers.values, index=list(custom_index))\n",
    "\n",
    "numbers2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the values in the series objects we've created, using indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The second value in series numbers is: ', numbers[1], '\\n')\n",
    "\n",
    "print('The second value in series numbers2 is: ', numbers2['b'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to address it using indices can be the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The first three values in series numbers2 are:')\n",
    "\n",
    "print(numbers2[:'c']) # numbers2['a':'c'] or numbers2[:3] or numbers2[1:3] or numbers2[:-3] work the same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at another way that we can create a series object: <b>Dictionaries</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_dict = {0:'California', 1:'New York', 2:'Virginia', 3:'Michigan', 4:'Texas', 5:'Nevada', 6:'Illinois'}\n",
    "\n",
    "locations = pd.Series(locations_dict)\n",
    "\n",
    "locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2 Data Frames\n",
    "Pandas DataFrame object is generally a two-dimensional, size mutable, potentially heterogeneous tabular data with axes that are labeled. It can be considered to be a special form of a Python dictionary or a numpy array.\n",
    "<br>Let's look at some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one of the most common ways to create a data frame\n",
    "age = {0:5, 1:21, 2:12, 3:10, 4:30, 5:13, 6:70}\n",
    "\n",
    "data1 = pd.DataFrame({'Name': names, 'Age': age, 'Location': locations})\n",
    "\n",
    "data1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's play with the index a little (both the column and row index) while introducing a new way to create a data frame with pandas (using an existing data frame)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = pd.DataFrame(data=data1).set_index('Name', drop=True)\n",
    "\n",
    "data2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a data frame using <b>numpy arrays</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = pd.DataFrame(np.arange(12).reshape(6, 2), columns=['Even', 'Odd'], index=list(custom_index))\n",
    "\n",
    "data3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Selection and Indexing of Data in Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at a couple of ways we access the columns of a data frame in pandas.\n",
    "<br><b>Note</b>: For this section, we'll use the '<b>data2</b>' data frame created earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2['Age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.Age is data2['Age']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both the above usages give the same result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll use this to operate on our data. We'll see how we can create a new column and enter values in that column by operating on an existing column.\n",
    "<br><br>Let's say that the 'Age' information in the dataset is 10 years old and we need to add a new column that has the adjusted values. Following is how we can accomplish that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2['Age_current'] = data2['Age'] + 10\n",
    "\n",
    "data2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use same sized multiple series of data to perform similar operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll look at some attributes that can be used by a pandas DataFrame object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns\n",
    "data2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index\n",
    "data2.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# values\n",
    "data2.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indexing the values\n",
    "data2.values[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's look at a bit more sophisticated methods for indexing.\n",
    "<br>We'll use the following:\n",
    "1. <b>iloc</b>: simple array like implicit integer indexer\n",
    "2. <b>loc</b>: uses explict index and column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first two columns and all rows except the first\n",
    "data2.iloc[1:, :2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first two columns and all rows except the first\n",
    "data2.loc['Tyisha':, :'Location']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use what we've learned in this section to apply a mask to our data and output only selected columns like we would do using an SQL query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.loc[data2.Age_current > 25, ['Age_current', 'Location']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Handling missing values in Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas uses two types of sentinels for representing null values and those are <b>None</b> and <b>NaN</b>.\n",
    "1. A <b>None</b> value is a python object generally used for representing null values in numpy arrays.\n",
    "2. A <b>NaN</b> value is a floating point value. When operating on data with 'NaN' values the operations tend to give out unwanted results.\n",
    "<br>We'll look at both in the following cells:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing1 = np.array([1, 2, 3, None])\n",
    "missing1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing2 = np.array([1, 2, 3, np.nan])\n",
    "missing2\n",
    "# missing2.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# operating a value with NaN will result in NaN\n",
    "print('Addition: (0 + {}) = {}'.format(np.nan, (0+np.nan)))\n",
    "print('Multiplication: (1 * {}) = {}'.format(np.nan, (1*np.nan)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>In Pandas, 'None' values are interchanged into 'NaN' values due to type casting as and when required. Let's look at an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example = pd.Series([1, 2, 3])\n",
    "example = pd.Series([1, 2, np.nan, 3, None])\n",
    "example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>Now we'll se how we can operate on null values in pandas. Following are some functions we'll be looking at:\n",
    "1. isnull( )\n",
    "2. notnull( )\n",
    "3. fillna( )\n",
    "4. dropna( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isnull returns a boolean mask for the data\n",
    "example.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notnull also returns a boolean mask for the data but it's opposite to isnull\n",
    "example.notnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use either of those masks to access the data\n",
    "example[example.notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll use the pandas data frame to see how the functions <b>fillna( )</b> and <b>dropna( )</b> work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing3 = data1.copy()\n",
    "missing3.loc[3:5, 'Age'] = np.nan\n",
    "missing3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping rows with null values\n",
    "missing3.dropna(inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's fill these values with the average of the non-null values.\n",
    "missing3.fillna(missing3.dropna()['Age'].mean(), inplace=True)\n",
    "missing3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Combining Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.1 concat( ) and append( )\n",
    "First we'll look at some simple functions that are used to combine datasets, <b>concat( ) and append( )</b>.\n",
    "<br>Let's look at pd.concat( ) first. \n",
    "<br><b>Note</b>: We'll use data frames for our examples, but series can be used just the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create two new data frames\n",
    "sample1 = pd.DataFrame(data={'A':[1, 2], 'B':[3, 4]}, index=[0, 1])\n",
    "sample2 = pd.DataFrame(data={'A':[5, 6], 'B':[7, 8]}, index=[0, 1])\n",
    "display('sample1', sample1, 'sample2', sample2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we'll see 2 ways of concatinating them\n",
    "\n",
    "# row-wise concatenation\n",
    "sample3 = pd.concat([sample1, sample2], axis=0)\n",
    "\n",
    "# column-wise concatenation\n",
    "sample4 = pd.concat([sample1, sample2], axis=1)\n",
    "\n",
    "display('sample3',sample3, 'sample4', sample4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important parameter for this function is '<b>join</b>'. Let's look at an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create two new dataframes\n",
    "sample5 = sample1.copy()\n",
    "sample6 = pd.DataFrame(data={'B':[9, 10], 'C':[11, 12]}, index=[0, 1])\n",
    "\n",
    "display('sample5', sample5, 'sample6', sample6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join these data frames over B using pd.concat()\n",
    "display('Joined', pd.concat([sample5, sample6], join='inner'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll look at <b>append( )</b> function. Though it gives a simmilar result as <b>concat( )</b> gives, but is a bit limited in its implementation as it only 'appends' row-wise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display('append', sample1.append(sample2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.2 Merge and Join\n",
    "Now we'll look at some of the more sophisticated methods for combining datasets.\n",
    "<br>First we'll see how to 'merge' datasets. We'll do that using <b>pd.merge( )</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left = pd.DataFrame({'A': [1, 2], 'B': [2, 3]})\n",
    "right = pd.DataFrame({'A': [4, 5, 6], 'B': [2, 2, 2]})\n",
    "\n",
    "display('left', left, 'right', right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outer join over column 'B'\n",
    "merger = pd.merge(left, right, on='B', how='outer', indicator=True)\n",
    "merger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to columns, we can also merge on index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new data frames\n",
    "df1 = pd.DataFrame({'Age':list(age.values())}, index=names)\n",
    "df2 = pd.DataFrame({'Dept_ID':[1, 2, 3, 4, 1, 3, 1]}, index=names)\n",
    "display('df1', df1, 'df2', df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's use index to merge\n",
    "pd.merge(df1, df2, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The <b>join( )</b> function does the same thing as it primarily works on index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df1.join(df2)\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at how we would merge data frames with different sizes and columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data frame for department \n",
    "df4 = pd.DataFrame({'Department_ID':[1, 2, 3, 4, 5], 'Department':['CSE', 'FRE', 'ECE', 'DS', 'BIO']})\n",
    "df4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data frame is strictly dedicated to the information about a department. 'DepartmentID' is the identifying column (primary key) in this case while it's also present in 'df3' as 'DeptID' (as the foreign key) which has the information about person name and their age. Now we'll see ways to combine these datasets.\n",
    "<br>As the names of the department ID columns are different in both dataframes, instead of just using the 'on' parameter as earlier, we'll have to specify columns from both of them data frames on which to join/merge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inner join\n",
    "pd.merge(df3, df4, left_on='Dept_ID', right_on='Department_ID', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outer join\n",
    "pd.merge(df4, df3, left_on='Department_ID', right_on='Dept_ID', how='outer', indicator=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Grouping and Aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we'll see how we can leverage the properties of a data frame and perform certain groupings and aggregations to better understand the data. Let's look at some examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new series for number of hours worked\n",
    "hours = pd.Series([30, 21, 40, 40, 35, 50, 15])\n",
    "hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple aggregations on series\n",
    "print('Hours sum:', hours.sum())\n",
    "print('Hours mean', hours.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add hours to df1\n",
    "df1['Hrs_Worked/week'] = hours.values\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate mean column-wise\n",
    "df1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate mean row-wise\n",
    "df1.mean(axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the <b>describe( )</b> function that is usually used to look at these aggregations in a data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# describe()\n",
    "df1.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll look at how to group the data and perform operations. This is one of the most important and widely used transformation on data frames.\n",
    "<br>The function we'll use here is <b>groupby( )</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new data frame with Dept_ID\n",
    "df5 = df1.join(df2).reset_index().rename(columns={'index':'Name'})\n",
    "df5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggregations on <b>groupby( )</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display names of people with maximum age in each department\n",
    "df5.groupby('Dept_ID')['Name', 'Age'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering on <b>groupby( )</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display departments with minimum age greater than 10\n",
    "df5.groupby('Dept_ID').filter(lambda x: x['Age'].min()>10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying functions over dataframe after <b>groupby( )</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize hours worked per week for each department\n",
    "def func_normalize(x):\n",
    "    x['Hrs_Worked/week'] = x['Hrs_Worked/week']/(x['Hrs_Worked/week'].sum())\n",
    "    return x\n",
    "    \n",
    "df5.groupby('Dept_ID').apply(func_normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Importing data in Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we'll look at one of the most common file formats used i.e. CSV.\n",
    "<br>There are many more formats supported by pandas. For the purpose of this exercise, we'll only look at importing CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get US states data \n",
    "population = pd.read_csv('data-USstates/state-population.csv')\n",
    "area = pd.read_csv('data-USstates/state-areas.csv')\n",
    "abbrev = pd.read_csv('data-USstates/state-abbrevs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abbrev.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's apply what we learned above and merge these three files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6 = pd.merge(area, abbrev, on='state')\n",
    "df6.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df7 = pd.merge(population, df6, left_on='state/region', right_on='abbreviation', how='outer').drop('abbreviation', axis=1)\n",
    "df7.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df7.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally lets apply a grouping to this data\n",
    "df7.groupby(['state/region', 'ages', 'year'])[df7.columns].filter(\n",
    "    lambda x: x['population'].min()>3000000 and x['area (sq. mi)'].min()>50000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Intro to Matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For all Matplotlib plots, we start by creating a figure and an axes.\n",
    "fig = plt.figure()\n",
    "ax = plt.axes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.axes()\n",
    "#Start point is 0 and end point is 10 number of samples is 1000\n",
    "x = np.linspace(0, 10, 1000)\n",
    "ax.plot(x, np.sin(x));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#can also be done like this\n",
    "plt.plot(x, np.sin(x));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compare sin and cos\n",
    "plt.plot(x, np.sin(x))\n",
    "plt.plot(x, np.cos(x));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Adjusting the Plot: Line Colors and Styles:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, np.sin(x - 0), color='blue')        # specify color by name\n",
    "plt.plot(x, np.sin(x - 1), color='g')           # short color code (rgbcmyk)\n",
    "plt.plot(x, np.sin(x - 2), color='0.75')        # Grayscale between 0 and 1\n",
    "plt.plot(x, np.sin(x - 3), color='#FFDD44')     # Hex code (RRGGBB from 00 to FF)\n",
    "plt.plot(x, np.sin(x - 4), color=(1.0,0.2,0.3)) # RGB tuple, values 0 to 1\n",
    "plt.plot(x, np.sin(x - 5), color='chartreuse'); # all HTML color names supported"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>adjusting line style:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, x + 0, linestyle='solid')\n",
    "plt.plot(x, x + 1, linestyle='dashed')\n",
    "plt.plot(x, x + 2, linestyle='dashdot')\n",
    "plt.plot(x, x + 3, linestyle='dotted');\n",
    "\n",
    "# For short, you can use the following codes:\n",
    "plt.plot(x, x + 4, linestyle='-')  # solid\n",
    "plt.plot(x, x + 5, linestyle='--') # dashed\n",
    "plt.plot(x, x + 6, linestyle='-.') # dashdot\n",
    "plt.plot(x, x + 7, linestyle=':');  # dotted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, x + 0, '-g')  # solid green\n",
    "plt.plot(x, x + 1, '--c') # dashed cyan\n",
    "plt.plot(x, x + 2, '-.k') # dashdot black\n",
    "plt.plot(x, x + 3, ':r');  # dotted red"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Labeling Plots:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, np.sin(x))\n",
    "plt.title(\"A Sine Curve\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"sin(x)\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, np.sin(x), '-g', label='sin(x)')\n",
    "plt.plot(x, np.cos(x), ':b', label='cos(x)')\n",
    "plt.axis('equal')\n",
    "\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In the previous section we looked at plt.plot/ax.plot to produce line plots. \n",
    "#It turns out that this same function can produce scatter plots as well:\n",
    "x = np.linspace(0, 10, 30)\n",
    "y = np.sin(x)\n",
    "\n",
    "plt.plot(x, y, 'o', color='black');\n",
    "\n",
    "#The third argument in the function call is a character that represents the type of symbol used for the plotting. \n",
    "#Just as you can specify options such as '-', '--'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A second, more powerful method of creating scatter plots is the plt.scatter\n",
    "plt.scatter(x, y, marker='o');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's use the US states data we imported earlier to create some visualizations in matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1, a= plt.subplots(1, 1, figsize=(16, 12))\n",
    "a.barh(area['state'], width=area['area (sq. mi)']/1000)\n",
    "a.set_xlabel('Area (*1000 sq. miles)')\n",
    "a.set_ylabel('State')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
